{
 "cells": [
  {
   "source": [
    "This notebook contains Jonathan's original csv writing code, but updated so that:\n",
    "- it uses the csv.writer() object to better handle quotes and special characters\n",
    "- includes the new functions/fields for additional puzzle metadata\n",
    "- strips the clue whitespace in advance\n",
    "- goes backwards (scrapes newest puzzles first)\n",
    "- added some basic error handling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import base packages we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from seaborn import set_style\n",
    "#set_style(\"whitegrid\")\n",
    "\n",
    "## this import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python\n",
    "    \n",
    "    returns generator to iterate over days in date range\n",
    "\n",
    "    modified here to go backwards\n",
    "    \"\"\"\n",
    "    for n in range(int((end_date - start_date).days))[::-1]:\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def get_clues_from_column(column):\n",
    "    \"\"\"\n",
    "    Converts list of divs to lines, clues, and answers\n",
    "    \n",
    "    Twice as many <div>s as hints/answers:\n",
    "    each line in column is \n",
    "    <div>Number</div>\n",
    "    <div>\n",
    "    Clue : <a href=\"asdf\">Answer</a>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    clues = []\n",
    "    answers = []\n",
    "    for i in range(int(len(column)/2)):\n",
    "        lines.append(int(column[2*i].text))\n",
    "        clues.append(column[2*i+1].text.replace(\",\", \";\").split(\":\")[0]) # This splits on commas too\n",
    "        answers.append(column[2*i+1].a.text)\n",
    "    return lines, clues, answers\n",
    "\n",
    "def get_clues(numclue):\n",
    "    \"\"\"\n",
    "    There are 2 <div class=\"numclue\">, \n",
    "    one for across hints/answers and one for down\n",
    "    \n",
    "    returns across and down as tuples\n",
    "    can be expanded with *\n",
    "    \"\"\"\n",
    "    across_divs = numclue[0].find_all('div')\n",
    "    down_divs = numclue[1].find_all('div')\n",
    "    \n",
    "    a_lines, a_clues, a_answers = get_clues_from_column(across_divs)\n",
    "    d_lines, d_clues, d_answers = get_clues_from_column(down_divs)\n",
    "    \n",
    "    across = (a_lines, a_clues, a_answers)\n",
    "    down = (d_lines, d_clues, d_answers)\n",
    "    \n",
    "    return across, down\n",
    "\n",
    "def get_stats():\n",
    "    '''returns a dict containing rows, columns, words, blocks, and missing letters'''\n",
    "    stat_block = {'rows' : '','columns' : '','words' : '','blocks' : '','missing' : ''}\n",
    "    stats = soup.find_all('div',{'id':'CPHContent_StatsData'})[0].find_all('span')\n",
    "    try:\n",
    "        stat_block['rows'] = re.search('(?<=Rows: )\\d+',stats[0].get_text()).group(0)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        stat_block['columns'] = re.search('(?<=Columns: )\\d+',stats[0].get_text()).group(0)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        stat_block['words'] = re.search('(?<=Words: )\\d+',stats[1].get_text()).group(0)\n",
    "    except:\n",
    "        pass\n",
    "    try: \n",
    "        stat_block['blocks'] = re.search('(?<=Blocks: )\\d+',stats[1].get_text()).group(0)\n",
    "    except: \n",
    "        pass\n",
    "    try:\n",
    "        stat_block['missing'] = re.search('({)(.+)(})',stats[4].get_text()).group(2)\n",
    "    except:\n",
    "        pass\n",
    "    return stat_block\n",
    "\n",
    "def get_authors():\n",
    "    '''returns a dict containing puzzle author and editor'''\n",
    "    author_info = soup.find_all('div', {'id' : 'CPHContent_AEGrid'})[0]\n",
    "    scraped_info = {'author' : '', 'editor': ''}\n",
    "    for index, div in enumerate(author_info):\n",
    "        try:\n",
    "            if div.get_text() == 'Author:':\n",
    "                scraped_info['author'] = list(author_info)[index+1].get_text()\n",
    "            elif div.get_text() == 'Editor:':\n",
    "                scraped_info['editor'] = list(author_info)[index+1].get_text()\n",
    "        except:\n",
    "            continue\n",
    "    return scraped_info\n",
    "\n",
    "def puz_info():\n",
    "    '''get the puzzle title and clue'''\n",
    "    try:\n",
    "        title = soup.find_all('h1', {'id' : 'PuzTitle'})[0].get_text()\n",
    "        clue = soup.find_all('h2', {'class' : 'keyclue'})[0].get_text()\n",
    "    except:\n",
    "        title = 'could not retrieve'\n",
    "        clue = 'could not retrieve'\n",
    "    return {'title' : title, 'clue' : clue}\n",
    "\n",
    "def print_column(lines, clues, answers):\n",
    "    for l,c,a in zip(lines, clues, answers):\n",
    "        print(\"%d - %s : %s\" % (l,c,a))\n",
    "        \n",
    "def write_clues_to_csv(date, clues, fname, direction):\n",
    "    for l,c,a in zip(*clues):\n",
    "        fname.write(\n",
    "            f\"{date.year},{date.month},{date.day},{date.strftime('%A')},\"\\\n",
    "            f\"{direction},{l},{c.strip()},{a.strip()},\"\\\n",
    "            f\"{puz_info()['title']},{puz_info()['clue']},\"\\\n",
    "            f\"{get_stats()['rows']},{get_stats()['columns']},\"\\\n",
    "            f\"{get_stats()['words']},{get_stats()['blocks']},{get_stats()['missing']}\\n\"\\\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_rows(date, clues, direction):\n",
    "    '''updated write_clues_to_csv to instead make the clues as a list of lists, for csv_writer'''\n",
    "    rows = []\n",
    "    for l,c,a in zip(*clues):\n",
    "        row = [\n",
    "            date.year,date.month,date.day,date.strftime('%A'),\n",
    "            direction,l,c.strip(),a.strip(),\n",
    "            get_authors()['author'], get_authors()['editor'],\n",
    "            puz_info()['title'],puz_info()['clue'],\n",
    "            get_stats()['rows'],get_stats()['columns'],\n",
    "            get_stats()['words'],get_stats()['blocks'],get_stats()['missing']\n",
    "            ]\n",
    "        rows.append(row)\n",
    "    return rows\n"
   ]
  },
  {
   "source": [
    "Running the cell below will start the scraping process!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Current puzzle: 1/15/1995'"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-b02a18abab10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mnumclue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'numclue'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0macross\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdown\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_clues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumclue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mcsv_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macross\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Across\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mcsv_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Down\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-32456e853f38>\u001b[0m in \u001b[0;36mmake_csv_rows\u001b[1;34m(date, clues, direction)\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%A'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mget_authors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'author'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_authors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'editor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mpuz_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpuz_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rows'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-605f4997fd47>\u001b[0m in \u001b[0;36mget_authors\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_authors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;34m'''returns a dict containing puzzle author and editor'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mauthor_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'CPHContent_AEGrid'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0mscraped_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'author'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'editor'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mfind_all\u001b[1;34m(self, name, attrs, recursive, text, limit, **kwargs)\u001b[0m\n\u001b[0;32m   1786\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1788\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1789\u001b[0m     \u001b[0mfindAll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_all\u001b[0m       \u001b[1;31m# BS3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m     \u001b[0mfindChildren\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_all\u001b[0m  \u001b[1;31m# BS2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m_find_all\u001b[1;34m(self, name, attrs, text, limit, generator, **kwargs)\u001b[0m\n\u001b[0;32m    781\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m                 \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;31m# If it's a Tag, make sure its name or attributes match.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m         \u001b[1;31m# Don't bother with Tags if we're searching for text.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2064\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, clear_output\n",
    "header = \"Year,Month,Day,Weekday,Direction,Line,Hint,Answer,Author,Editor,PuzTitle,PuzClue,NumRows,NumCols,NumWords,NumBlocks,MissingLetters\".split(',')\n",
    "\n",
    "with open(\"nick-xword.csv\",'a',newline='') as f:\n",
    "    start_date = date(1995, 1, 1)\n",
    "    end_date = date(1995, 2, 1) # go up to 2021,5,1\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(header)\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        try:\n",
    "            day_of_week = single_date.strftime('%A')\n",
    "            date_for_url = single_date.strftime(\"%#m/%#d/%Y\") # replace # with - on mac/linux\n",
    "            # following two lines use ipython to avoid a long string of print statements; can be safely commented out\n",
    "            clear_output(wait=True)\n",
    "            display(f\"Current puzzle: {date_for_url}\")\n",
    "            html = urlopen(\"https://www.xwordinfo.com/Crossword?date=\"+date_for_url)\n",
    "            soup = BeautifulSoup(html,\"html.parser\")\n",
    "            numclue = soup.find_all('div', {'class': 'numclue'})\n",
    "            across, down = get_clues(numclue)\n",
    "            csv_writer.writerows(make_csv_rows(single_date, across, \"Across\"))\n",
    "            csv_writer.writerows(make_csv_rows(single_date, down, \"Down\"))\n",
    "        except Exception as e:\n",
    "            with open(\"nick-errors.txt\", \"w+\") as log:\n",
    "                log.write(f\"Error getting puzzle for {single_date}: {e}\")"
   ]
  },
  {
   "source": [
    "Test the output file with pandas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    Author  PuzTitle\n",
       "0        Sidney L. Robbins         3\n",
       "1             Bryant White         2\n",
       "2            Ernie Furtado         2\n",
       "3         Fran & Lou Sabin         2\n",
       "4              Rich Norris         2\n",
       "5            Randolph Ross         2\n",
       "6             A.J. Santora         1\n",
       "7   Nancy Nicholson Joline         1\n",
       "8            Walter Covell         1\n",
       "9     Stephanie Spadaccini         1\n",
       "10      Stanley B. Whitten         1\n",
       "11          Richard Hughes         1\n",
       "12         Norma Steinberg         1\n",
       "13            Judith Perry         1\n",
       "14          Manny Nosowsky         1\n",
       "15         Albert J. Klaus         1\n",
       "16              Henry Hook         1\n",
       "17            Harvey Estes         1\n",
       "18         Gregory E. Paul         1\n",
       "19          Frances Hansen         1\n",
       "20           Chuck Deodene         1\n",
       "21        Christopher Page         1\n",
       "22       Charles E. Gersch         1\n",
       "23   Wayne Robert Williams         1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Author</th>\n      <th>PuzTitle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sidney L. Robbins</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bryant White</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ernie Furtado</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fran &amp; Lou Sabin</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rich Norris</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Randolph Ross</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A.J. Santora</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Nancy Nicholson Joline</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Walter Covell</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Stephanie Spadaccini</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Stanley B. Whitten</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Richard Hughes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Norma Steinberg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Judith Perry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Manny Nosowsky</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Albert J. Klaus</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Henry Hook</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Harvey Estes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Gregory E. Paul</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Frances Hansen</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Chuck Deodene</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Christopher Page</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Charles E. Gersch</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Wayne Robert Williams</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "df = pd.read_csv(\"nick-xword.csv\")\n",
    "\n",
    "# Puzzle count by author\n",
    "df.groupby(['Author'])['PuzTitle'].nunique().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Weekday    Author                \n",
       "Monday     Sidney L. Robbins         3\n",
       "Saturday   Randolph Ross             2\n",
       "Friday     Chuck Deodene             1\n",
       "Thursday   A.J. Santora              1\n",
       "Wednesday  Stephanie Spadaccini      1\n",
       "           Stanley B. Whitten        1\n",
       "           Norma Steinberg           1\n",
       "Tuesday    Richard Hughes            1\n",
       "           Rich Norris               1\n",
       "           Gregory E. Paul           1\n",
       "           Christopher Page          1\n",
       "           Albert J. Klaus           1\n",
       "Thursday   Harvey Estes              1\n",
       "           Fran & Lou Sabin          1\n",
       "           Bryant White              1\n",
       "Sunday     Nancy Nicholson Joline    1\n",
       "Friday     Fran & Lou Sabin          1\n",
       "Sunday     Henry Hook                1\n",
       "           Frances Hansen            1\n",
       "           Ernie Furtado             1\n",
       "           Bryant White              1\n",
       "Saturday   Rich Norris               1\n",
       "           Charles E. Gersch         1\n",
       "Monday     Walter Covell             1\n",
       "           Ernie Furtado             1\n",
       "Friday     Manny Nosowsky            1\n",
       "           Judith Perry              1\n",
       "Wednesday  Wayne Robert Williams     1\n",
       "Name: PuzTitle, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "df.groupby(['Weekday','Author'])['PuzTitle'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37664bit8ebcdbbb0f8548a88014d2138d5dd4f5",
   "display_name": "Python 3.7.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "89550c41512397be3b92a88a74e3b1e8549c4151dd6ce085be64a8e2e8a2e248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}