{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import base packages we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from seaborn import set_style\n",
    "#set_style(\"whitegrid\")\n",
    "\n",
    "## this import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python\n",
    "    \n",
    "    returns generator to iterate over days in date range\n",
    "\n",
    "    modified here to go backwards\n",
    "    \"\"\"\n",
    "    for n in range(int((end_date - start_date).days))[::-1]:\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def get_clues_from_column(column):\n",
    "    \"\"\"\n",
    "    Converts list of divs to lines, clues, and answers\n",
    "    \n",
    "    Twice as many <div>s as hints/answers:\n",
    "    each line in column is \n",
    "    <div>Number</div>\n",
    "    <div>\n",
    "    Clue : <a href=\"asdf\">Answer</a>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    clues = []\n",
    "    answers = []\n",
    "    for i in range(int(len(column)/2)):\n",
    "        lines.append(int(column[2*i].text))\n",
    "        clues.append(column[2*i+1].text.replace(\",\", \";\").split(\":\")[0]) # This splits on commas too\n",
    "        answers.append(column[2*i+1].a.text)\n",
    "    return lines, clues, answers\n",
    "\n",
    "def get_clues(numclue):\n",
    "    \"\"\"\n",
    "    There are 2 <div class=\"numclue\">, \n",
    "    one for across hints/answers and one for down\n",
    "    \n",
    "    returns across and down as tuples\n",
    "    can be expanded with *\n",
    "    \"\"\"\n",
    "    across_divs = numclue[0].find_all('div')\n",
    "    down_divs = numclue[1].find_all('div')\n",
    "    \n",
    "    a_lines, a_clues, a_answers = get_clues_from_column(across_divs)\n",
    "    d_lines, d_clues, d_answers = get_clues_from_column(down_divs)\n",
    "    \n",
    "    across = (a_lines, a_clues, a_answers)\n",
    "    down = (d_lines, d_clues, d_answers)\n",
    "    \n",
    "    return across, down\n",
    "\n",
    "def print_column(lines, clues, answers):\n",
    "    for l,c,a in zip(lines, clues, answers):\n",
    "        print(\"%d - %s : %s\" % (l,c,a))\n",
    "        \n",
    "def write_clues_to_csv(date, clues, fname, direction):\n",
    "    for l,c,a in zip(*clues):\n",
    "        fname.write(f\"{date.year},{date.month},{date.day},{date.strftime('%A')},{direction},{l},{c},{a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4/30/2021\n",
      "4/29/2021\n",
      "4/28/2021\n",
      "4/27/2021\n",
      "4/26/2021\n",
      "4/25/2021\n",
      "4/24/2021\n",
      "4/23/2021\n",
      "4/22/2021\n",
      "4/21/2021\n",
      "4/20/2021\n",
      "4/19/2021\n",
      "4/18/2021\n",
      "4/17/2021\n",
      "4/16/2021\n",
      "4/15/2021\n",
      "4/14/2021\n",
      "4/13/2021\n",
      "4/12/2021\n",
      "4/11/2021\n",
      "4/10/2021\n",
      "4/9/2021\n",
      "4/8/2021\n",
      "4/7/2021\n",
      "4/6/2021\n",
      "4/5/2021\n",
      "4/4/2021\n",
      "4/3/2021\n",
      "4/2/2021\n",
      "4/1/2021\n",
      "3/31/2021\n",
      "3/30/2021\n",
      "3/29/2021\n",
      "3/28/2021\n",
      "3/27/2021\n",
      "3/26/2021\n",
      "3/25/2021\n",
      "3/24/2021\n",
      "3/23/2021\n",
      "3/22/2021\n",
      "3/21/2021\n",
      "3/20/2021\n",
      "3/19/2021\n",
      "3/18/2021\n",
      "3/17/2021\n",
      "3/16/2021\n",
      "3/15/2021\n",
      "3/14/2021\n",
      "3/13/2021\n",
      "3/12/2021\n",
      "3/11/2021\n",
      "3/10/2021\n",
      "3/9/2021\n",
      "3/8/2021\n",
      "3/7/2021\n",
      "3/6/2021\n",
      "3/5/2021\n",
      "3/4/2021\n",
      "3/3/2021\n",
      "3/2/2021\n",
      "3/1/2021\n",
      "2/28/2021\n",
      "2/27/2021\n",
      "2/26/2021\n",
      "2/25/2021\n",
      "2/24/2021\n",
      "2/23/2021\n",
      "2/22/2021\n",
      "2/21/2021\n",
      "2/20/2021\n",
      "2/19/2021\n",
      "2/18/2021\n",
      "2/17/2021\n",
      "2/16/2021\n",
      "2/15/2021\n",
      "2/14/2021\n",
      "2/13/2021\n",
      "2/12/2021\n",
      "2/11/2021\n",
      "2/10/2021\n",
      "2/9/2021\n",
      "2/8/2021\n",
      "2/7/2021\n",
      "2/6/2021\n",
      "2/5/2021\n",
      "2/4/2021\n",
      "2/3/2021\n",
      "2/2/2021\n",
      "2/1/2021\n",
      "1/31/2021\n",
      "1/30/2021\n",
      "1/29/2021\n",
      "1/28/2021\n",
      "1/27/2021\n",
      "1/26/2021\n",
      "1/25/2021\n",
      "1/24/2021\n",
      "1/23/2021\n",
      "1/22/2021\n",
      "1/21/2021\n",
      "1/20/2021\n",
      "1/19/2021\n",
      "1/18/2021\n",
      "1/17/2021\n",
      "1/16/2021\n",
      "1/15/2021\n",
      "1/14/2021\n",
      "1/13/2021\n",
      "1/12/2021\n",
      "1/11/2021\n",
      "1/10/2021\n",
      "1/9/2021\n",
      "1/8/2021\n",
      "1/7/2021\n",
      "1/6/2021\n",
      "Could not get puzzle for 2021-01-06\n",
      "1/5/2021\n",
      "1/4/2021\n",
      "1/3/2021\n",
      "1/2/2021\n",
      "Could not get puzzle for 2021-01-02\n",
      "1/1/2021\n",
      "12/31/2020\n",
      "12/30/2020\n",
      "12/29/2020\n",
      "12/28/2020\n",
      "12/27/2020\n",
      "12/26/2020\n",
      "12/25/2020\n",
      "12/24/2020\n",
      "12/23/2020\n",
      "12/22/2020\n",
      "12/21/2020\n",
      "12/20/2020\n",
      "Could not get puzzle for 2020-12-20\n",
      "12/19/2020\n",
      "12/18/2020\n",
      "12/17/2020\n",
      "12/16/2020\n",
      "12/15/2020\n",
      "12/14/2020\n",
      "12/13/2020\n",
      "12/12/2020\n",
      "12/11/2020\n",
      "12/10/2020\n",
      "12/9/2020\n",
      "12/8/2020\n",
      "12/7/2020\n",
      "12/6/2020\n",
      "12/5/2020\n",
      "12/4/2020\n",
      "12/3/2020\n",
      "12/2/2020\n",
      "12/1/2020\n",
      "11/30/2020\n",
      "11/29/2020\n",
      "11/28/2020\n",
      "11/27/2020\n",
      "11/26/2020\n",
      "11/25/2020\n",
      "11/24/2020\n",
      "11/23/2020\n",
      "11/22/2020\n",
      "11/21/2020\n",
      "11/20/2020\n",
      "11/19/2020\n",
      "11/18/2020\n",
      "Could not get puzzle for 2020-11-18\n",
      "11/17/2020\n",
      "11/16/2020\n",
      "11/15/2020\n",
      "11/14/2020\n",
      "11/13/2020\n"
     ]
    }
   ],
   "source": [
    "with open(\"nick-xword.csv\", 'w+', encoding='utf-8') as csv_file:\n",
    "    csv_file.write(\"Year,Month,Day,Weekday,Direction,Line,Hint,Answer\\n\")\n",
    "\n",
    "    start_date = date(1995, 1, 1)\n",
    "    end_date = date(2021, 5, 1) # go up to 2021,5,1\n",
    "\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        try:\n",
    "            day_of_week = single_date.strftime('%A')\n",
    "            date_for_url = single_date.strftime(\"%#m/%#d/%Y\") # replace # with - on mac/linux\n",
    "            print(date_for_url)\n",
    "            html = urlopen(\"https://www.xwordinfo.com/Crossword?date=\"+date_for_url)\n",
    "            soup = BeautifulSoup(html,\"html.parser\")\n",
    "            numclue = soup.find_all('div', {'class': 'numclue'})\n",
    "            across, down = get_clues(numclue)\n",
    "            #print(\"across\")\n",
    "            #print_column(*across)\n",
    "            #print(\"Down\")\n",
    "            #print_column(*down)\n",
    "            write_clues_to_csv(single_date, across, csv_file, \"Across\")\n",
    "            write_clues_to_csv(single_date, down, csv_file, \"Down\")\n",
    "        except:\n",
    "            print(f\"Could not get puzzle for {single_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- 6/7/2000 is a uniclue puzzle, not included for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across\n",
      "1 - Rodeo rope  : LASSO\n",
      "6 - City north of Des Moines  : AMES\n",
      "10 - Sch. supporters  : PTAS\n",
      "14 - Esaus wife  : ADAH\n",
      "18 - Travel section advertiser  : USAIR\n",
      "19 - ___ wire  : LIVE\n",
      "20 - Elektra baritone  : OREST\n",
      "21 - Army mascot  : MULE\n",
      "22 - ROBS  : CARLREINER\n",
      "24 - BRIDGETS  : PETERFONDA\n",
      "26 - Neighbor of Scot.  : ENG\n",
      "27 - JOHNS  : TEXRITTER\n",
      "29 - Escapee  : ELUDER\n",
      "30 - Anarchist Goldman  : EMMA\n",
      "33 - Gladly; in olden times  : FAIN\n",
      "34 - Night rumblers  : SNORERS\n",
      "35 - Asia-Africa link  : SINAI\n",
      "37 - Org. once headed by Lewis Strauss  : AEC\n",
      "40 - Half of D  : CCL\n",
      "41 - Conceit  : EGO\n",
      "42 - Exaggerators suffix  : EST\n",
      "43 - Yucca fiber  : ISTLE\n",
      "44 - NANCYS  : FRANKSINATRA\n",
      "48 - Theyre checked at checkpoints  : VISAS\n",
      "49 - Record collections  : FILES\n",
      "50 - Adam was his father  : SETH\n",
      "51 - Yellow-breasted bird  : CHAT\n",
      "55 - Pale  : ASHY\n",
      "56 - Cockatoo cousin  : MACAW\n",
      "57 - Approved model : STD\n",
      "58 - Contrary girl  : MARY\n",
      "59 - Seventh Muslim month  : RAJAB\n",
      "61 - Gershwins ___ It a Pity?  : ISNT\n",
      "63 - Flustered one  : DITHERER\n",
      "67 - Luau staple  : POI\n",
      "69 - BRANFORDS  : ELLISMARSALIS\n",
      "72 - Actress Charlotte  : RAE\n",
      "73 - Monotonous  : UNVARIED\n",
      "75 - Organic compound  : ENOL\n",
      "76 - ___ people go  : LETMY\n",
      "78 - Adolescent  : TEEN\n",
      "79 - Engine starter : IGN\n",
      "81 - Stage actor Edmund and others  : KEANS\n",
      "83 - Group with the hit Waterloo  : ABBA\n",
      "86 - Silk wrap  : SARI\n",
      "87 - Vier minus eins  : DREI\n",
      "89 - Jumping-off point?  : LEDGE\n",
      "90 - Pines  : TREES\n",
      "91 - JEFFS  : LLOYDBRIDGES\n",
      "94 - Innisfree and others  : ISLES\n",
      "95 - Rain protector  : MAC\n",
      "98 - Be in the red  : OWE\n",
      "99 - UniT of sound  : BEL\n",
      "100 - Road curve  : ESS\n",
      "101 - Liturgical music  : CHANT\n",
      "102 - Removes to a distance  : ELOIGNS\n",
      "104 - And thats not all  : ETAL\n",
      "106 - Fliers org.  : USAF\n",
      "107 - Behave arrogantly  : LORDIT\n",
      "108 - LAURAS  : BRUCEDERN\n",
      "112 - To ___ their golden eyes : OPE\n",
      "115 - JAMIE LEES  : TONYCURTIS\n",
      "117 - CHRISTIES  : HUGHHEFNER\n",
      "120 - German donkey  : ESEL\n",
      "121 - Shake awake  : ROUSE\n",
      "122 - Ship to Colchis  : ARGO\n",
      "123 - Renaissance instruments  : LUTES\n",
      "124 - Give a hand  : DEAL\n",
      "125 - Snack  : NOSH\n",
      "126 - Longtime New Yorker editor  : ROSS\n",
      "127 - Worth of the stage  : IRENE\n",
      "Down\n",
      "1 - The Women playwright  : LUCE\n",
      "2 - Straight ___ arrow  : ASAN\n",
      "3 - MARIAS  : SARGENTSHRIVER\n",
      "4 - Part of R.S.V.P.  : SIL\n",
      "5 - Bruins great  : ORR\n",
      "6 - Sam Shepards ___ of the Mind  : ALIE\n",
      "7 - Pert lass  : MINX\n",
      "8 - Did you ___ !  : EVER\n",
      "9 - Typeface line  : SERIF\n",
      "10 - Sign up early  : PREENLIST\n",
      "11 - Four : TETR\n",
      "12 - Enzyme suffix  : ASE\n",
      "13 - Muscles  : STRENGTH\n",
      "14 - Jeannes love  : AMOUR\n",
      "15 - Firth of Tay port  : DUNDEE\n",
      "16 - Birch-family trees  : ALDERS\n",
      "17 - Lord of San Simeon  : HEARST\n",
      "20 - Study of light  : OPTICS\n",
      "23 - Due point : ETA\n",
      "25 - Nonplus  : FLOOR\n",
      "28 - Changes course; nautically  : TACKS\n",
      "31 - Rubber region  : MALAYA\n",
      "32 - ___ van der Rohe  : MIES\n",
      "34 - Provide space for  : SEAT\n",
      "35 - Hindu god  : SIVA\n",
      "36 - Osiriss wife  : ISIS\n",
      "37 - Cordial  : AFFABLE\n",
      "38 - Folk singer Andersen  : ERIC\n",
      "39 - Channel port  : CALAIS\n",
      "45 - Certain reporters  : NEWSMEN\n",
      "46 - Canios wife in Pagliacci  : NEDDA\n",
      "47 - Crowning point  : ACME\n",
      "52 - SHARIS  : HARRYBELAFONTE\n",
      "53 - Scope  : AREA\n",
      "54 - City in the Crusades  : TYRE\n",
      "56 - Neighbor of Algeria  : MALI\n",
      "57 - Caressed  : STROKED\n",
      "60 - O.T. bood after Isa.  : JER\n",
      "62 - Big-band vocalist Wynn  : NAN\n",
      "64 - Hypochondriacs preoccupation  : ILLNESS\n",
      "65 - Gifts for fathers  : TIES\n",
      "66 - Margarets fathers monogram  : HST\n",
      "67 - Sets  : PUTS\n",
      "68 - Militarily fit  : ONEA\n",
      "70 - I wanderd till ___ : IDIED\n",
      "71 - Heavy tool  : SLEDGE\n",
      "74 - Deep blue  : ANIL\n",
      "77 - Mason or Norman  : MARSHA\n",
      "80 - Xjclmzit obwny; e.g.  : GIBBERISH\n",
      "82 - Long time  : AGES\n",
      "84 - Stayed  : BEEN\n",
      "85 - Office abbr.  : ASST\n",
      "87 - Decline  : DOWNTURN\n",
      "88 - Some whiskies  : RYES\n",
      "89 - New Hampshire state flower  : LILAC\n",
      "90 - Personal quirks  : TICS\n",
      "92 - Raymond Smullyan topic  : LOGIC\n",
      "93 - Rounded and notched; as a leaf  : RETUSE\n",
      "95 - Softened  : MELTED\n",
      "96 - Words before cannon or wire  : ALOOSE\n",
      "97 - Pupils protection  : CORNEA\n",
      "103 - Pastoral poem  : IDYLL\n",
      "105 - Zigeunerliebe composer  : LEHAR\n",
      "106 - Durham campus : UNH\n",
      "108 - Heat measures; for short  : BTUS\n",
      "109 - Spanish peso  : DURO\n",
      "110 - Quiche ingredients  : EGGS\n",
      "111 - Greek letters  : RHOS\n",
      "113 - Ball ___  : PEEN\n",
      "114 - European tongue  : ERSE\n",
      "116 - Kangas child  : ROO\n",
      "118 - Big name in New Haven  : ELI\n",
      "119 - Soft coat  : FUR\n"
     ]
    }
   ],
   "source": [
    "with open(\"xword2.csv\", 'w+', encoding='utf-8') as csv_file:\n",
    "    #csv_file = open(\"xword2.csv\", \"w+\")\n",
    "    csv_file.write(\"Year,Month,Day,Weekday,Direction,Line,Hint,Answer\\n\")\n",
    "\n",
    "    single_date = date(1994,6,19)\n",
    "\n",
    "    html = urlopen(\"https://www.xwordinfo.com/Crossword?date=6/19/1994\")\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    numclue = soup.find_all('div', {'class': 'numclue'})\n",
    "    across, down = get_clues(numclue)\n",
    "    print(\"across\")\n",
    "    print_column(*across)\n",
    "    print(\"Down\")\n",
    "    print_column(*down)\n",
    "    write_clues_to_csv(single_date, across, csv_file, \"Across\")\n",
    "    write_clues_to_csv(single_date, down, csv_file, \"Down\")\n",
    "\n",
    "#csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Smuggler's nemesis, maybe \", ' SHOREPATROL']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 11: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 11: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a73d49b95bb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xword.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\jonathan\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\jonathan\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\jonathan\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\jonathan\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2157\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2158\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2159\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 11: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"xword.csv\")\n",
    "\n",
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37664bit8ebcdbbb0f8548a88014d2138d5dd4f5",
   "display_name": "Python 3.7.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "89550c41512397be3b92a88a74e3b1e8549c4151dd6ce085be64a8e2e8a2e248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}